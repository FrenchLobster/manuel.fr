---
sidebar_position: 2
---

## Llama3.1

1. Llama3.1 est un chatbot développé par Meta AI qui utilise le traitement du langage naturel (NLP) pour travailler sur les entrées humaines. Llama3.1 est sorti quelques semaines après Llama3, lui-même sorti un peu près un an après Llama2. Llama2 a démocratisé les LLM OpenSource en étant le premier qui avait de bonnes performance.

Llama3.1 se décline actuellement en trois versions, Llama3.1 8b, Llama3.1 70b et Llama3.1 240B. On peut faire tourner Llama3 8b sur un Mac avec 8 Go de mémoire vive. Pour faire tourner le modèle 70B, il faut 40 Gb de mémoire et pour faire tourner le modèle 240B, il faut utiliser un cluster de Mac, c'est à dire faire tourner plusieurs Macs à la fois.

2. *Il peut générer du texte, répondre à des questions complexes et avoir des conversations naturelles et engageantes avec les utilisateurs.*

3. *Il peut expliquer des concepts, écrire des poèmes et du code, résoudre des puzzles logiques, ou même nommer vos animaux de compagnie.*

Pour obtenir plus d'informations rendez-vous sur [la page Llama3](https://ollama.ai/library/llama3/) de ollama.


## Dolphin-llama3

[Dolphin-Llama3](https://ollama.com/library/dolphin-llama3) est une version non censurée et fine tunée du modèle Llama3. il faudrait le comparer précisement sur des tâche comme l'aide à la programmation avec Llama3 pour mieux comprendre les différences entre ces deux modèles.

Seule la version 8b existe en version uncensored avec Llam3, il faut savoir que Llama3 est beaucoup plus permissif que Llama2 et que l'utilité d'une version Unscensored présente moins d'intérêt.

Sinon il existe aussi ce modèle ]LLama3-Uncensored](https://ollama.com/gurubot/llama3-guru-uncensored) sur une page perso de modèle ollama. 



## Falcon et Falcon2

[Falcon](https://ollama.com/library/falcon) est intéressant car c'est un modèle qui n'est pas américain et donc on peut espérer qu'il soit plus interntional. C'est aussi le modèle le plus volumineux avec une version en 120GB. Toutefois ils ont sorti un nouveau modèle plus rapide et plus léger avec [Falcon2](https://ollama.com/library/falcon2) qui est un modèle 11B qui prend donc 6,4B sur le disque dur et qui tourne sur des ordinateurs à partir de 16G de Ram, on peut donc le faire tourner sur un Mac mini M1 16Go que l'on voit passer régulièrement en dessous de 600 € d'occasion sur LeBonCoin.



## Mixtral 8x7B

1. *Mixtral 8x7B est un modèle d’IA de Mistral AI qui surpasse Llama2 70B dans la plupart des benchmarks, offrant une inférence 6 fois plus rapide.*

2. *Il utilise une architecture de modèle clairsemée et huit blocs de rétroaction différents dans le Transformer.*

3. *Il prend en charge des fonctionnalités multilingues, une excellente génération de code et une fenêtre contextuelle de 32 000 octets.*

Pour obtenir ce modèle rendez-vous sur [le site](https://ollama.ai/library/mixtral/) de ollama.


## Gemma

Google fait également de l'OpenSource et a mis à disposition le modèle Gemma qui a connu quelques problèmes au début et qu'il faut retester.

Pour obtenir ce modèle rendez-vous sur [la page Gemma](https://ollama.ai/library/gemma/) de ollama.
